#!/usr/bin/env python3
import requests as rq
import re
from argparse import ArgumentParser as aAP
from urllib.parse import urljoin, urlunparse, urlparse
import pathlib

parser = aAP(description="A simple script for downloading files from Sci-Hub",
             epilog="This script works by parsing the response "
             "sent back from the server. "
             "Since different Sci-Hub mirrors may have different interfaces, "
             "and their layouts may change in the future, "
             "there is NO GUARANTEE that this script works on every mirror, "
             "or will continue to work on currently working mirrors "
             "in the future. ")
parser.add_argument("--version", "-V",
                    action='version',
                    version="%(prog)s v0.3.1 by KAC")
parser.add_argument("doi",
                    type=str,
                    # nargs='*',  # to deal with space in doi
                    help="The DOI string of the document. "
                    "If the string contains spaces, it must be quoted")
parser.add_argument("--proxy",
                    type=str,
                    # default="socks5h://127.0.0.1:9150",
                    help="Requests-type proxy argument. "
                    "Used for both HTTP and HTTPS. "
                    "Use socks5h://127.0.0.1:9150 "
                    "for TOR browser socks5 proxy. "
                    # "Pass an empty string to disable proxy. "
                    "Default: "
                    "no proxy"
                    # "socks5h://127.0.0.1:9150"
                    )
parser.add_argument('-m', "--mirror", 
                    type=str,
                    action='append',
                    help="Domain of scihub mirror to use. "
                    "Can specify multiple times to try different mirrors. "
                    "Default: "
                    "https://sci-hub.se/")
parser.add_argument("-o", "--output", 
                    type=str,
                    help="Save file with this name stem. "
                    "File extension part will always follow from mirror. "
                    "Default: "
                    "the remote file name")
parser.add_argument("--dir",
                    type=str,
                    help="Download to this directory. "
                    "Relative path to current working directory. "
                    "May contain (Unix-style) ~ for home dir. "
                    "Default: "
                    "current working directory")
parser.add_argument("--chunk",
                    type=int,
                    default=8192,
                    help="Size of each download chunk, in bytes. "
                    "Default: "
                    "8192")
parser.add_argument("--useragent",
                    type=str,
                    default="Mozilla/5.0 "
                    "(Windows NT 10.0; Win64; x64; rv:78.0) "
                    "Gecko/20100101 Firefox/78.0",
                    help="The user agent string used. "
                    "If this script fails to get results "
                    "but you can find the requested papers on the website, "
                    "try changing this. "
                    "Default: "
                    "(TOR Browser on Win10 x64) "
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:78.0) "
                    "Gecko/20100101 Firefox/78.0 ")
parser.add_argument("--verbose", "-v",
                    action='store_true',
                    help="Display verbose information")
args = parser.parse_args()


def humanByteUnitString(s: int) -> str:
    if s >= 1024 ** 2:
        return f"{s / (1024 ** 2) :.2f} MB"
    elif s >= 1024:
        return f"{s / 1024 :.2f} KB"
    else:
        return f"{s} B"


def verbosePrint(msg: str, isVerbose: bool = args.verbose) -> None:
    if isVerbose:
        print(msg)


if args.dir is None:
    args.dir = pathlib.Path.cwd()
else:
    # TODO better check this in dl stage?
    try:
        joinedDir = pathlib.Path.cwd() / pathlib.Path(args.dir).expanduser()
        args.dir = joinedDir.resolve(strict=True)
        if not args.dir.is_dir():
            raise FileNotFoundError
    except FileNotFoundError:
        print(str(joinedDir), "is not a valid directory")
        quit()
verbosePrint(f"Download directory: {str(args.dir)}")

if args.mirror is None:
    # apply default
    args.mirror = ("https://sci-hub.se/", )

proxyDict = {'http': args.proxy, 'https': args.proxy} \
    if (args.proxy is not None and args.proxy != "") \
    else None
# check proxy
if proxyDict is not None:
    try:
        verbosePrint("Testing proxy ...")
        rq.get("https://example.com/",
               proxies=proxyDict,
               headers={'User-Agent': args.useragent})
    except (rq.exceptions.InvalidURL, rq.exceptions.ProxyError):
        print("Proxy config is invalid")
        quit()
    except rq.ConnectionError:
        print("Failed connecting to requested proxy")
        quit()
    except Exception as e:
        print("Unknown exception when testing proxy connectivity: ")
        print(e)
        quit()
    else:
        verbosePrint(f"Using proxy {args.proxy}")
else:
    print("WARNING: No proxy configured")


# if args.doi is None:
#     args.doi = input("Enter the DOI string: ")
# else:
#     args.doi = " ".join(args.doi)
args.doi = re.sub("^(https?://)?(dx\\.|www\\.)?doi(\\.org/|:|/)\\s*",
                  '',
                  args.doi.strip())
# TODO better DOI checking
if len(args.doi) == 0 or ' ' in args.doi or not args.doi[0].isalnum():
    print(f"Cannot parse input DOI \"{args.doi}\"")
    quit()
verbosePrint(f"Input DOI: {args.doi}")

# TODO check if different mirrors have different response link
rePattern = re.compile("\"location\\.href=.?'(.+?)\\?download=true'")


def tryFetchDocFromSciHubMirror(mirrorURL: str, docDOI: str) -> bool:
    verbosePrint("Checking if mirror is online ...")
    try:
        if rq.get(mirrorURL,
                  proxies=proxyDict,
                  headers={'User-Agent': args.useragent}).status_code != 200:
            raise rq.exceptions.ConnectionError
    except (rq.exceptions.MissingSchema,
            rq.exceptions.InvalidSchema,
            rq.exceptions.InvalidURL):
        print(f"{mirrorURL} does not seem valid")
        return False
    except rq.exceptions.ConnectionError:
        print(f"Cannot connect to {mirrorURL}")
        return False

    verbosePrint("Querying " + urljoin(mirrorURL, docDOI) + " ...")
    firstResponse = rq.get(urljoin(mirrorURL, docDOI),
                           proxies=proxyDict,
                           headers={'User-Agent': args.useragent})
    # TODO better method of checking first return
    if (not firstResponse.headers['Content-Type'].startswith('text/html')) \
            or len(firstResponse.text.strip('\n ')) == 0:
        print("Empty response. Maybe no search result?")
        return False

    verbosePrint("Findind download link from response ...")
    possibleDLLinkLst = list()
    for line in firstResponse.text.splitlines():
        # TODO better method of extracting download link
        # TODO better un-escaping url
        # enforce https if no scheme
        if '?download=true' in line:
            dlURL = urlunparse(
                urlparse(rePattern.search(line).group(1)
                         .replace(r'\\', '\\').replace(r'\/', '/'),
                         scheme="https",
                         allow_fragments=False)
            )
            verbosePrint(f"Link found: {dlURL}")
            possibleDLLinkLst.append(dlURL)
    if len(possibleDLLinkLst) == 0:
        print("No download link detected in response. \n"
              "Response format is not understood, "
              "or file may no be available on this mirror.")
        return False
    elif len(possibleDLLinkLst) > 1:
        print("Multiple download links found. \n"
              "They are: ")
        for lnk in possibleDLLinkLst:
            print(lnk)
        print("Using only the first link")
        possibleDLLinkLst = possibleDLLinkLst[:1]
    docURL = possibleDLLinkLst[0]

    verbosePrint(f"Downloading from {docURL} ...")
    dlFilename = urlparse(docURL).path.rsplit('/', 1)[-1]
    if args.output is not None:
        dlFilename = args.output + '.' + dlFilename.rsplit('.')[-1]
    dlTargetPath = args.dir / dlFilename
    verbosePrint(f"Downloading to {str(dlTargetPath)}")
    downloadedSize = 0
    lastLineLen = 0
    dlMsg = None
    try:
        fileHandle = dlTargetPath.open('wb')
    except PermissionError:
        # TODO better handling of exceptions
        print(f"Cannot write to target path \"{str(dlTargetPath)}\"")
        return False
    with rq.get(docURL,
                proxies=proxyDict,
                stream=True,
                headers={'User-Agent': args.useragent}) as dlResponse:
        fileSize = dlResponse.headers.get('Content-Length', None)
        if fileSize is not None:
            fileSize = int(fileSize)
            print("File size: " + humanByteUnitString(fileSize))
        else:
            print("File size unknown")
        with fileHandle:
            for dataChunk in dlResponse.iter_content(chunk_size=args.chunk):
                fileHandle.write(dataChunk)
                downloadedSize += len(dataChunk)
                if fileSize is not None:
                    dlMsg = "Downloaded " \
                        + f"{downloadedSize / fileSize * 100 :.2f}%"
                else:
                    dlMsg = "Downloaded " \
                        + humanByteUnitString(downloadedSize)
                print(dlMsg, end='')
                lenDLMsg = len(dlMsg)
                print(" " * (lastLineLen - lenDLMsg), end='\r')
                lastLineLen = lenDLMsg
    print("\nDownload done")
    return True


if not any(tryFetchDocFromSciHubMirror(mirrorURL, args.doi)
           for mirrorURL
           in args.mirror):
    print("Download failed: No mirror seems to have this document")
